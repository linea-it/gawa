{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the ga-wazpy code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a few packages. The package scikit-image is needed. Install it locally using conda <br>\n",
    "in the terminal and after restart the kernel. \n",
    "\n",
    "Run these 2 lines below in terminal and after that restart kernel:\n",
    "python -m pip install -U --user pip\n",
    "python -m pip install -U --user scikit-image\n",
    "\n",
    "Transformation from DECam g and r to V absolute magnitude: V = g - 0.58*(g-r) - 0.01 (Jester 2005, from SDSS to V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "warn_level = 'ignore'\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(warn_level)\n",
    "    os.environ[\"PYTHONWARNINGS\"] = warn_level\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "from lib.multithread import split_equal_area_in_threads\n",
    "from lib.utils import hpx_split_survey\n",
    "from lib.utils import read_FitsCat, create_directory\n",
    "from lib.utils import create_mosaic_footprint, create_survey_footprint_from_mosaic\n",
    "from lib.utils import add_key_to_fits, concatenate_clusters\n",
    "from lib.utils import tile_radius, create_tile_specs\n",
    "from lib.utils import read_mosaicFitsCat_in_disc, create_directory \n",
    "from lib.utils import read_mosaicFootprint_in_disc\n",
    "from lib.utils import add_clusters_unique_id\n",
    "from lib.gawa import compute_cmd_masks, compute_dslices, create_gawa_directories\n",
    "from lib.gawa import gawa_tile, tile_dir_name\n",
    "from lib.gawa import cl_duplicates_filtering\n",
    "\n",
    "import parsl\n",
    "from parsl import python_app\n",
    "from parsl.config import Config\n",
    "from parsl.executors.threads import ThreadPoolExecutor\n",
    "\n",
    "local_threads = Config(\n",
    "    executors=[\n",
    "        ThreadPoolExecutor(\n",
    "            max_threads=1,\n",
    "            label='local_threads'\n",
    "        )\n",
    "    ],\n",
    "    internal_tasks_max_threads=1\n",
    ")\n",
    "\n",
    "parsl.load(local_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def gawa_thread_call(param, thread_id):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        param (_type_): _description_\n",
    "        thread_id (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "    from astropy.table import Table\n",
    "\n",
    "    workdir = param['out_paths']['workdir']\n",
    "\n",
    "    all_tiles = read_FitsCat(os.path.join(workdir, param['admin']['tiling']['tiles_filename']))\n",
    "    tiles = all_tiles[(all_tiles['thread_id']==int(thread_id))]    \n",
    "    print ('THREAD ', int(thread_id))\n",
    "\n",
    "    for it in range(0, len(tiles)):\n",
    "        tile_dir = tile_dir_name(workdir, int(tiles['id'][it]) )\n",
    "        print ('..... Tile ', int(tiles['id'][it]))\n",
    "\n",
    "        create_directory(tile_dir)\n",
    "        create_gawa_directories(tile_dir, param['out_paths']['gawa'])\n",
    "        param['out_paths']['tile_dir'] = tile_dir\n",
    "\n",
    "        tile_radius_deg = tile_radius(param['admin']['tiling'])\n",
    "        tile_specs = create_tile_specs(tiles[it], tile_radius_deg, param['admin'])\n",
    "        data_star_tile = read_mosaicFitsCat_in_disc(param['starcat'][param['survey']], tiles[it], tile_radius_deg)   \n",
    "        data_fp_tile   = read_mosaicFootprint_in_disc (param['footprint'][param['survey']], tiles[it], tile_radius_deg)\n",
    "\n",
    "        if param['verbose'] >= 2:\n",
    "            t = Table(data_star_tile)\n",
    "            t.write(os.path.join(tile_dir, param['out_paths']['gawa']['files'],\"starcat.fits\"),overwrite=True)\n",
    "            t = Table(data_fp_tile)\n",
    "            t.write(os.path.join(tile_dir, param['out_paths']['gawa']['files'], \"footprint.fits\"),overwrite=True)\n",
    "  \n",
    "        gawa_tile(\n",
    "            tile_specs, param['isochrone_masks'][param['survey']],\n",
    "            data_star_tile, param['starcat'][param['survey']],\n",
    "            data_fp_tile, param['footprint'][param['survey']],\n",
    "            param['gawa_cfg'], param['admin'], param['out_paths'], param['verbose']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gawa_concatenate(param):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        param (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # concatenate all tiles \n",
    "    all_tiles = read_FitsCat(os.path.join(param['out_paths']['workdir'], param['admin']['tiling']['tiles_filename']))\n",
    "\n",
    "    list_results = []\n",
    "    for it in range(0, len(all_tiles)):\n",
    "        tile_dir = tile_dir_name(param['out_paths']['workdir'], int(all_tiles['id'][it]) )\n",
    "        list_results.append(os.path.join(tile_dir, param['out_paths']['gawa']['results']))\n",
    "        \n",
    "    concatenate_clusters(list_results, os.path.join(param['out_paths']['workdir'],'clusters0.fits')) \n",
    "\n",
    "    # final filtering \n",
    "    data_clusters0 = read_FitsCat(os.path.join(param['out_paths']['workdir'],'clusters0.fits'))\n",
    "    data_clusters0f = cl_duplicates_filtering(data_clusters0, param['gawa_cfg'], 'survey')\n",
    "    # create unique index with decreasing SNR \n",
    "    data_clusters = add_clusters_unique_id(data_clusters0f, param['gawa_cfg']['clkeys'])\n",
    "    data_clusters.write(os.path.join(param['out_paths']['workdir'],'clusters.fits'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config file as online argument \n",
    "confg = \"gawa.json\"\n",
    "\n",
    "# read config file\n",
    "with open(confg) as fstream:\n",
    "    param = json.load(fstream)\n",
    "\n",
    "# Working & output directories \n",
    "workdir = param['out_paths']['workdir']\n",
    "create_directory(workdir)\n",
    "create_directory(os.path.join(workdir, 'tiles'))\n",
    "print ('Survey : ', param['survey'])\n",
    "print ('workdir : ', workdir)\n",
    "tiles_filename = os.path.join(workdir, param['admin']['tiling']['tiles_filename'])\n",
    "\n",
    "# create required data structure if not exist and update config \n",
    "if not param['input_data_structure'][param['survey']]['footprint_hpx_mosaic']:\n",
    "    create_mosaic_footprint(param['footprint'][param['survey']], os.path.join(workdir, 'footprint'))\n",
    "    param['footprint'][param['survey']]['mosaic']['dir'] = os.path.join(workdir, 'footprint')  \n",
    "\n",
    "# split_area:\n",
    "if param['input_data_structure'][param['survey']]['footprint_hpx_mosaic']: \n",
    "    survey_footprint = os.path.join(workdir, 'survey_footprint.fits')\n",
    "    if not os.path.isfile(survey_footprint):\n",
    "        create_survey_footprint_from_mosaic(param['footprint'][param['survey']], survey_footprint)\n",
    "else:\n",
    "    survey_footprint = param['footprint'][param['survey']]['survey_footprint']\n",
    "\n",
    "if not os.path.isfile(tiles_filename):\n",
    "    ntiles = hpx_split_survey(survey_footprint, param['footprint'][param['survey']], param['admin']['tiling'], tiles_filename)\n",
    "    n_threads, thread_ids = split_equal_area_in_threads(param['admin']['nthreads_max'], tiles_filename)\n",
    "    add_key_to_fits(tiles_filename, thread_ids, 'thread_id', 'int')\n",
    "else:\n",
    "    dat = read_FitsCat(tiles_filename)\n",
    "    ntiles, n_threads = len(dat), np.amax(dat['thread_id']) \n",
    "    thread_ids = dat['thread_id']\n",
    "    \n",
    "print ('Ntiles / Nthreads = ', ntiles, ' / ', n_threads)\n",
    "\n",
    "# prepare dslices \n",
    "compute_dslices(param['isochrone_masks'][param['survey']], param['gawa_cfg']['dslices'], workdir)\n",
    "\n",
    "# compute cmd_masks \n",
    "print ('Compute CMD masks')\n",
    "compute_cmd_masks(param['isochrone_masks'][param['survey']], param['out_paths'], param['gawa_cfg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = list()\n",
    "\n",
    "with tqdm(total=len(thread_ids), file=sys.stdout) as pbar:\n",
    "    pbar.set_description(\"Submit Parsls Tasks\")\n",
    "\n",
    "    for i in np.unique(thread_ids):\n",
    "        futures.append(gawa_thread_call(param, i))\n",
    "        pbar.update()\n",
    "\n",
    "#for i in np.unique(thread_ids): \n",
    "#    futures.append(gawa_thread_call(param, i))\n",
    "    \n",
    "#for p in futures:\n",
    "#    p.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tasks Done:\")\n",
    "\n",
    "with tqdm(total=len(futures), file=sys.stdout) as pbar2:\n",
    "    is_done = list()\n",
    "    done_count = 0\n",
    "    while is_done.count(True) != len(futures):\n",
    "        is_done = list()\n",
    "        for f in futures:\n",
    "            is_done.append(f.done())\n",
    "\n",
    "        if is_done.count(True) != done_count:\n",
    "            done_count = is_done.count(True)\n",
    "            pbar2.reset(total=len(futures))  \n",
    "            pbar2.update(done_count)\n",
    "\n",
    "        if done_count < len(futures):\n",
    "            sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gawa_concatenate(param)\n",
    "print ('all done folks!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
